{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-12T17:35:43.340227Z",
     "start_time": "2026-02-12T17:35:43.332227Z"
    }
   },
   "outputs": [],
   "source": [
    "# Configs\n",
    "from rdflib import Graph, Namespace, RDF, RDFS, OWL, Literal, XSD\n",
    "from rdflib.namespace import FOAF\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import os\n",
    "\n",
    "OUTPUT_DIR = \"outputs\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "DATA_DIR = \"data\"\n",
    "SCHEMA_FILE = os.path.join(OUTPUT_DIR, \"schema.ttl\")\n",
    "BASE_URI = \"http://kg-course.io/food-nutrition/\"\n",
    "\n",
    "RECIPES_CSV = os.path.join(DATA_DIR, \"Recipes.csv\")\n",
    "NUTRITION_CSV = os.path.join(DATA_DIR, \"Nutrition.csv\")\n",
    "RESTAURANTS_CSV = os.path.join(DATA_DIR, \"Restaurants.csv\")\n",
    "REVIEWS_TXT = os.path.join(DATA_DIR, \"Reviews.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-12T17:35:43.355227Z",
     "start_time": "2026-02-12T17:35:43.345227Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_schema():\n",
    "    g = Graph()\n",
    "    \n",
    "    BASE = Namespace(BASE_URI)\n",
    "    SCHEMA = Namespace(\"http://schema.org/\")\n",
    "    \n",
    "    g.bind(\"\", BASE)\n",
    "    g.bind(\"schema\", SCHEMA)\n",
    "    g.bind(\"rdf\", RDF)\n",
    "    g.bind(\"rdfs\", RDFS)\n",
    "    g.bind(\"owl\", OWL)\n",
    "    g.bind(\"xsd\", XSD)\n",
    "    g.bind(\"foaf\", FOAF)\n",
    "    \n",
    "    classes = [\n",
    "        (BASE.Recipe, SCHEMA.Recipe, \"Recipe\"),\n",
    "        (BASE.Nutrition, SCHEMA.NutritionInformation, \"Nutrition\"),\n",
    "        (BASE.Restaurant, SCHEMA.Restaurant, \"Restaurant\"),\n",
    "        (BASE.Review, SCHEMA.Review, \"Review\"),\n",
    "        (BASE.Ingredient, SCHEMA.Ingredient, \"Ingredient\"),\n",
    "        (BASE.Author, SCHEMA.Person, \"Author\"),\n",
    "        (BASE.Cuisine, None, \"Cuisine\")\n",
    "    ]\n",
    "    \n",
    "    for cls, schema_cls, label in classes:\n",
    "        g.add((cls, RDF.type, RDFS.Class))\n",
    "        g.add((cls, RDF.type, OWL.Class))\n",
    "        g.add((cls, RDFS.label, Literal(label, lang=\"en\")))\n",
    "        if schema_cls:\n",
    "            g.add((cls, RDFS.subClassOf, schema_cls))\n",
    "    \n",
    "    # For integration and SPARQL queries (connections)\n",
    "    properties = [\n",
    "        # Recipe\n",
    "        (BASE.hasNutrition, BASE.Recipe, BASE.Nutrition),\n",
    "        (BASE.hasReview, BASE.Recipe, BASE.Review),\n",
    "        (BASE.hasCuisine, BASE.Recipe, BASE.Cuisine),\n",
    "        (BASE.hasIngredient, BASE.Recipe, BASE.Ingredient),\n",
    "        \n",
    "        # Restaurant\n",
    "        (BASE.servesCuisine, BASE.Restaurant, BASE.Cuisine),\n",
    "        \n",
    "        # Review\n",
    "        (BASE.mentionsIngredient, BASE.Review, BASE.Ingredient),\n",
    "    ]\n",
    "    \n",
    "    for prop, domain, range_cls in properties:\n",
    "        g.add((prop, RDF.type, RDF.Property))\n",
    "        g.add((prop, RDF.type, OWL.ObjectProperty))\n",
    "        g.add((prop, RDFS.domain, domain))\n",
    "        g.add((prop, RDFS.range, range_cls))\n",
    "    \n",
    "    # For attributes\n",
    "    datatype_props = [\n",
    "        (BASE.hasAggregateSentiment, BASE.Recipe, XSD.float),\n",
    "        (BASE.hasSentimentScore, BASE.Review, XSD.float),\n",
    "        (BASE.hasSentimentLabel, BASE.Review, XSD.string),\n",
    "        (BASE.hasOnlineDelivery, BASE.Restaurant, XSD.boolean),\n",
    "        (BASE.hasTableBooking, BASE.Restaurant, XSD.boolean),\n",
    "        (BASE.averageCostForTwo, BASE.Restaurant, XSD.float),\n",
    "    ]\n",
    "    \n",
    "    for prop, domain, range_type in datatype_props:\n",
    "        g.add((prop, RDF.type, RDF.Property))\n",
    "        g.add((prop, RDF.type, OWL.DatatypeProperty))\n",
    "        g.add((prop, RDFS.domain, domain))\n",
    "        g.add((prop, RDFS.range, range_type))\n",
    "    \n",
    "    return g\n",
    "\n",
    "schema_graph = create_schema()\n",
    "print(f\"{len(schema_graph)} triples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-12T17:35:43.683293Z",
     "start_time": "2026-02-12T17:35:43.365226Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_diagram():\n",
    "    G = nx.DiGraph()\n",
    "    \n",
    "    nodes = ['Recipe', 'Nutrition', 'Restaurant', 'Review', 'Ingredient', 'Author', 'Cuisine']\n",
    "    G.add_nodes_from(nodes)\n",
    "    \n",
    "    edges = [ # With labels\n",
    "        ('Recipe', 'Nutrition', 'hasNutrition'),\n",
    "        ('Recipe', 'Review', 'hasReview'),\n",
    "        ('Recipe', 'Cuisine', 'hasCuisine'),\n",
    "        ('Recipe', 'Ingredient', 'hasIngredient'),\n",
    "        ('Restaurant', 'Cuisine', 'servesCuisine'),\n",
    "        ('Review', 'Recipe', 'itemReviewed'),\n",
    "        ('Review', 'Author', 'author'),\n",
    "        ('Review', 'Ingredient', 'mentionsIngredient'),\n",
    "    ]\n",
    "    \n",
    "    for src, tgt, label in edges:\n",
    "        G.add_edge(src, tgt, label=label)\n",
    "    \n",
    "    plt.figure(figsize=(14, 10))\n",
    "    pos = nx.spring_layout(G, k=2, iterations=50, seed=42)\n",
    "    colors = {\n",
    "        'Recipe': '#3498db', 'Restaurant': '#3498db', # Core entities\n",
    "        'Nutrition': '#2ecc71', # Structured data\n",
    "        'Review': '#e74c3c', # Unstructured data\n",
    "        'Ingredient': '#f39c12', # Extracted entities\n",
    "        'Author': '#9b59b6', # Person\n",
    "        'Cuisine': '#1abc9c' # Bridge entity\n",
    "    }\n",
    "    node_colors = [colors[n] for n in G.nodes()]\n",
    "    nx.draw_networkx_nodes(G, pos, node_color=node_colors, node_size=3000, alpha=0.9)\n",
    "    nx.draw_networkx_labels(G, pos, font_size=11, font_weight='bold')\n",
    "    nx.draw_networkx_edges(G, pos, edge_color='gray', arrows=True, arrowsize=20, width=2, connectionstyle='arc3,rad=0.1')\n",
    "    \n",
    "    edge_labels = nx.get_edge_attributes(G, 'label')\n",
    "    nx.draw_networkx_edge_labels(G, pos, edge_labels, font_size=9, bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.7))\n",
    "    plt.title('KG schema\\nfood & nutrition', fontsize=14, fontweight='bold', pad=20)\n",
    "    \n",
    "    # Legend\n",
    "    legend = [\n",
    "        mpatches.Patch(color='#3498db', label='Core entities'),\n",
    "        mpatches.Patch(color='#2ecc71', label='Structured data'),\n",
    "        mpatches.Patch(color='#e74c3c', label='Unstructured data'),\n",
    "        mpatches.Patch(color='#f39c12', label='Extracted entities'),\n",
    "        mpatches.Patch(color='#9b59b6', label='Person'),\n",
    "        mpatches.Patch(color='#1abc9c', label='Bridge entity')\n",
    "    ]\n",
    "    plt.legend(handles=legend, loc='upper left', fontsize=9)\n",
    "    plt.axis(False)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save\n",
    "    diagram_file = os.path.join(OUTPUT_DIR, \"schema_diagram.png\")\n",
    "    plt.savefig(diagram_file, dpi=300, bbox_inches='tight', facecolor='white')\n",
    "    plt.show()\n",
    "    print(f\"Diagram: {diagram_file}\")\n",
    "\n",
    "create_diagram()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-12T17:35:43.698297Z",
     "start_time": "2026-02-12T17:35:43.688294Z"
    }
   },
   "outputs": [],
   "source": [
    "schema_graph.serialize(destination=SCHEMA_FILE, format=\"turtle\")\n",
    "\n",
    "print(f\"Schema location: {SCHEMA_FILE}\")\n",
    "print(f\"Triples: {len(schema_graph)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-12T17:35:43.713805Z",
     "start_time": "2026-02-12T17:35:43.702297Z"
    }
   },
   "outputs": [],
   "source": [
    "# Display schema statistics\n",
    "print(\"TASK 1\")\n",
    "\n",
    "classes = list(schema_graph.subjects(RDF.type, RDFS.Class))\n",
    "properties = list(schema_graph.subjects(RDF.type, RDF.Property))\n",
    "\n",
    "print(f\"\\nClasses: {len(classes)}\")\n",
    "for cls in classes:\n",
    "    label = schema_graph.value(cls, RDFS.label)\n",
    "    print(f\"  - {label}\")\n",
    "\n",
    "print(f\"\\nProperties: {len(properties)}\\n\")\n",
    "\n",
    "print(\"Recipe <-> Restaurant via Cuisine\")\n",
    "print(\"Recipe <-> Nutrition (1:1 linking)\")\n",
    "print(\"Recipe <-> Review (sentiment)\")\n",
    "print(\"Ingredient <-> Wikidata (external KG)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-12T17:35:43.744804Z",
     "start_time": "2026-02-12T17:35:43.732805Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import hashlib\n",
    "from rdflib import Graph, Namespace, RDF, Literal, XSD\n",
    "import os\n",
    "LIMIT = 10000\n",
    "BASE = Namespace(BASE_URI)\n",
    "SCHEMA = Namespace(\"http://schema.org/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-12T17:35:43.760162Z",
     "start_time": "2026-02-12T17:35:43.746805Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean(s):\n",
    "    return \"\" if pd.isna(s) else str(s).strip()\n",
    "\n",
    "def extract_cuisines(text):\n",
    "    if not text:\n",
    "        return []\n",
    "    text = text.lower()\n",
    "    cuisines = ['italian', 'chinese', 'indian', 'mexican', 'japanese', 'thai', 'french', 'greek', 'spanish', 'korean', 'vietnamese', 'american', 'mediterranean', 'asian', 'european']\n",
    "    return [c for c in cuisines if c in text]\n",
    "\n",
    "def load_csv(filepath, nrows=None):\n",
    "    df = pd.read_csv(filepath, nrows=nrows, sep=';', on_bad_lines='skip') # Skip bad lines and use semicolon delimiter\n",
    "    if len(df.columns) > 1:\n",
    "        return df\n",
    "\n",
    "# Load CSVs\n",
    "recipes_df = load_csv(RECIPES_CSV, nrows=LIMIT)\n",
    "print(f\"{len(recipes_df)} recipes\")\n",
    "nutrition_df = load_csv(NUTRITION_CSV, nrows=LIMIT)\n",
    "print(f\"{len(nutrition_df)} nutrition records\")\n",
    "restaurants_df = load_csv(RESTAURANTS_CSV, nrows=LIMIT)\n",
    "print(f\"{len(restaurants_df)} restaurants\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-12T17:35:43.887673Z",
     "start_time": "2026-02-12T17:35:43.875674Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize graph with schema for converting to RDF\n",
    "g = Graph()\n",
    "g.parse(SCHEMA_FILE, format=\"turtle\")\n",
    "\n",
    "recipe_name_to_uri = {}\n",
    "cuisine_uris = {}\n",
    "cuisine_counter = 0\n",
    "print(f\"{len(g)} triples from schema\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-12T17:35:45.980754Z",
     "start_time": "2026-02-12T17:35:43.892676Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert Recipes\n",
    "def find_col(df, search_terms):\n",
    "    \n",
    "    if isinstance(search_terms, str):\n",
    "        search_terms = [search_terms]\n",
    "    \n",
    "    for col in df.columns:\n",
    "        for term in search_terms:\n",
    "            if term.lower() in col.lower():\n",
    "                return col\n",
    "    \n",
    "    # Return first column as fallback\n",
    "    return df.columns[0]\n",
    "\n",
    "cuisine_counter = 0\n",
    "\n",
    "for idx, row in recipes_df.iterrows():\n",
    "    # print(idx) # debug\n",
    "    recipe_uri = BASE[f\"recipe_{idx}\"]\n",
    "    \n",
    "    g.add((recipe_uri, RDF.type, BASE.Recipe)) # Add type to created URI\n",
    "    \n",
    "    # Add properties\n",
    "    name = clean(row.get('Name'))\n",
    "    if name:\n",
    "        g.add((recipe_uri, SCHEMA.name, Literal(name)))\n",
    "        recipe_name_to_uri[name] = recipe_uri\n",
    "    \n",
    "    if pd.notna(row.get('CookTime')):\n",
    "        g.add((recipe_uri, SCHEMA.cookTime, Literal(str(row['CookTime']))))\n",
    "    \n",
    "    if pd.notna(row.get('PrepTime')):\n",
    "        g.add((recipe_uri, SCHEMA.prepTime, Literal(str(row['PrepTime']))))\n",
    "    \n",
    "    if pd.notna(row.get('DatePublished')):\n",
    "        g.add((recipe_uri, SCHEMA.datePublished, Literal(str(row['DatePublished']))))\n",
    "    \n",
    "    if pd.notna(row.get('RecipeCategory')):\n",
    "        g.add((recipe_uri, SCHEMA.recipeCategory, Literal(clean(row['RecipeCategory']))))\n",
    "    \n",
    "    if pd.notna(row.get('Keywords')):\n",
    "        g.add((recipe_uri, SCHEMA.keywords, Literal(clean(row['Keywords']))))\n",
    "    \n",
    "    if pd.notna(row.get('RecipeIngredientParts')):\n",
    "        g.add((recipe_uri, SCHEMA.recipeIngredient, Literal(clean(row['RecipeIngredientParts']))))\n",
    "    \n",
    "    # Extract cuisines\n",
    "    category = clean(row.get('RecipeCategory', '')) + ' ' + clean(row.get('Keywords', ''))\n",
    "    for cuisine in extract_cuisines(category):\n",
    "        if cuisine not in cuisine_uris: # Check\n",
    "            cuisine_uri = BASE[f\"cuisine_{cuisine_counter}\"]\n",
    "            g.add((cuisine_uri, RDF.type, BASE.Cuisine))\n",
    "            g.add((cuisine_uri, SCHEMA.name, Literal(cuisine)))\n",
    "            cuisine_uris[cuisine] = cuisine_uri # Store\n",
    "            cuisine_counter += 1\n",
    "        else:\n",
    "            cuisine_uri = cuisine_uris[cuisine] # Get\n",
    "        g.add((recipe_uri, BASE.hasCuisine, cuisine_uri)) # Link recipe to cuisine\n",
    "\n",
    "        \n",
    "        g.add((recipe_uri, BASE.hasCuisine, cuisine_uri)) # Link recipe to cuisine\n",
    "\n",
    "print(f\"{len(recipes_df)} Recipes\")\n",
    "print(f\"{len(g)} triples\")\n",
    "\n",
    "# print(f\"Built lookup for {len(recipe_name_to_uri)} recipe names\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-12T17:35:47.841044Z",
     "start_time": "2026-02-12T17:35:46.032264Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert nutrition and link to recipes\n",
    "\n",
    "print(\"Nutrition cols:\", nutrition_df.columns.tolist())\n",
    "linked = 0\n",
    "for idx, row in nutrition_df.iterrows():\n",
    "    # Create URI\n",
    "    name_col = [col for col in nutrition_df.columns if 'name' in col.lower()][0]\n",
    "    name = clean(row[name_col])\n",
    "    # nutrition_uri = BASE[f\"nutrition_{nutrition_counter}\"]\n",
    "    nutrition_uri = BASE[f\"nutrition_{idx}\"]\n",
    "    \n",
    "    g.add((nutrition_uri, RDF.type, BASE.Nutrition))\n",
    "    \n",
    "    # Link to recipe\n",
    "    recipe_uri = recipe_name_to_uri.get(name)\n",
    "    if recipe_uri:\n",
    "        g.add((recipe_uri, BASE.hasNutrition, nutrition_uri))\n",
    "        linked += 1\n",
    "    \n",
    "    # Add nutritional values\n",
    "    for field, predicate in [\n",
    "        ('Calories', SCHEMA.calories),\n",
    "        ('FatContent', SCHEMA.fatContent),\n",
    "        ('SaturatedFatContent', SCHEMA.saturatedFatContent),\n",
    "        ('CholesterolContent', SCHEMA.cholesterolContent),\n",
    "        ('SodiumContent', SCHEMA.sodiumContent),\n",
    "        ('CarbohydrateContent', SCHEMA.carbohydrateContent),\n",
    "        ('FiberContent', SCHEMA.fiberContent),\n",
    "        ('SugarContent', SCHEMA.sugarContent),\n",
    "        ('ProteinContent', SCHEMA.proteinContent)\n",
    "    ]:\n",
    "        if pd.notna(row.get(field)):\n",
    "            g.add((nutrition_uri, predicate, Literal(float(row[field]), datatype=XSD.float)))\n",
    "\n",
    "print(f\"Converted {len(nutrition_df)} nutrition records\")\n",
    "print(f\"Linked {linked} to recipes\")\n",
    "print(f\"Graph count: {len(g)} triples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-12T17:35:49.961621Z",
     "start_time": "2026-02-12T17:35:47.890902Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert Restaurants\n",
    "print(\"Recipe columns:\", recipes_df.columns.tolist())\n",
    "print(\"Nutrition columns:\", nutrition_df.columns.tolist())\n",
    "print(\"Restaurant columns:\", restaurants_df.columns.tolist())\n",
    "def find_col(df, search_terms):\n",
    "    if isinstance(search_terms, str):\n",
    "        search_terms = [search_terms]\n",
    "    \n",
    "    for col in df.columns:\n",
    "        for term in search_terms:\n",
    "            if term.lower() in col.lower():\n",
    "                return col\n",
    "    return df.columns[0]\n",
    "\n",
    "restaurants_df.columns = restaurants_df.columns.str.strip() # Normalize column names\n",
    "\n",
    "rest_id_col = find_col(restaurants_df, ['Restaurant ID', 'ID', 'RestaurantID'])\n",
    "name_col = find_col(restaurants_df, ['Restaurant Name', 'Name', 'RestaurantName'])\n",
    "city_col = find_col(restaurants_df, ['City', 'Locality', 'Location'])\n",
    "cuisines_col = find_col(restaurants_df, ['Cuisines', 'Cuisine'])\n",
    "cost_col = find_col(restaurants_df, ['Average cost of two in USD', 'Average Cost for two', 'Average Cost for Two'])\n",
    "\n",
    "# print(\"Names of cols:\")\n",
    "# print(\"  ID      :\", rest_id_col)\n",
    "# print(\"  Name    :\", name_col)\n",
    "# print(\"  City    :\", city_col)\n",
    "# print(\"  Cuisines:\", cuisines_col)\n",
    "\n",
    "for idx, row in restaurants_df.iterrows():\n",
    "    restaurant_uri = BASE[f\"restaurant_{idx}\"]\n",
    "\n",
    "    g.add((restaurant_uri, RDF.type, BASE.Restaurant))\n",
    "\n",
    "    # Name\n",
    "    if pd.notna(row.get(name_col)):\n",
    "        g.add((restaurant_uri, SCHEMA.name, Literal(clean(row.get(name_col)))))\n",
    "\n",
    "    # Address\n",
    "    if pd.notna(row.get('Address')):\n",
    "        g.add((restaurant_uri, SCHEMA.address, Literal(clean(row.get('Address')))))\n",
    "\n",
    "    # City using detected city column\n",
    "    if pd.notna(row.get(city_col)):\n",
    "        g.add((restaurant_uri, SCHEMA.addressLocality, Literal(clean(row.get(city_col)))))\n",
    "\n",
    "    # Country\n",
    "    if pd.notna(row.get('Country')):\n",
    "        g.add((restaurant_uri, SCHEMA.addressCountry, Literal(clean(row.get('Country')))))\n",
    "\n",
    "    # Geo coordinates\n",
    "    if pd.notna(row.get('Latitude')) and pd.notna(row.get('Longitude')):\n",
    "        lat, lon = float(row.get('Latitude')), float(row.get('Longitude'))\n",
    "        if lat != 0 and lon != 0:\n",
    "            geo_uri = BASE[f\"geo_{idx}\"]\n",
    "            g.add((geo_uri, RDF.type, SCHEMA.GeoCoordinates))\n",
    "            g.add((geo_uri, SCHEMA.latitude, Literal(lat, datatype=XSD.float)))\n",
    "            g.add((geo_uri, SCHEMA.longitude, Literal(lon, datatype=XSD.float)))\n",
    "            g.add((restaurant_uri, SCHEMA.geo, geo_uri))\n",
    "\n",
    "    # Aggregate rating\n",
    "    if pd.notna(row.get('Aggregate rating')):\n",
    "        g.add((restaurant_uri, SCHEMA.aggregateRating,\n",
    "                   Literal(float(row.get('Aggregate rating')), datatype=XSD.float)))\n",
    "\n",
    "    # Cost\n",
    "    if pd.notna(row.get(cost_col)):\n",
    "        g.add((restaurant_uri, BASE.averageCostForTwo, Literal(float(row.get(cost_col)), datatype=XSD.float))) \n",
    "\n",
    "    # Booleans\n",
    "    if pd.notna(row.get('Has Online delivery')):\n",
    "        has_delivery = str(row.get('Has Online delivery')).strip().lower() in ['yes', 'true', '1']\n",
    "        g.add((restaurant_uri, BASE.hasOnlineDelivery, Literal(has_delivery, datatype=XSD.boolean)))\n",
    "    if pd.notna(row.get('Has Table booking')):\n",
    "        has_booking = str(row.get('Has Table booking')).strip().lower() in ['yes', 'true', '1']\n",
    "        g.add((restaurant_uri, BASE.hasTableBooking, Literal(has_booking, datatype=XSD.boolean)))\n",
    "\n",
    "    # Cuisines using detected cuisines col\n",
    "    cuisines_text = clean(row.get(cuisines_col, ''))\n",
    "    for cuisine in extract_cuisines(cuisines_text):\n",
    "        cuisine_uri = cuisine_uris.get(cuisine)\n",
    "        if not cuisine_uri:\n",
    "            cuisine_uri = BASE[f\"cuisine_{cuisine_counter}\"]\n",
    "            g.add((cuisine_uri, RDF.type, BASE.Cuisine))\n",
    "            g.add((cuisine_uri, SCHEMA.name, Literal(cuisine)))\n",
    "            cuisine_uris[cuisine] = cuisine_uri\n",
    "        g.add((restaurant_uri, BASE.servesCuisine, cuisine_uri))\n",
    "\n",
    "print(f\"Converted {len(restaurants_df)} restaurants\")\n",
    "print(f\"Found {len(cuisine_uris)} unique cuisines\")\n",
    "print(f\"Graph now: {len(g)} triples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-12T17:35:54.605095Z",
     "start_time": "2026-02-12T17:35:50.012133Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save KG\n",
    "output_file = os.path.join(OUTPUT_DIR, \"KEN4256-structured-KG-team2.ttl\")\n",
    "g.serialize(destination=output_file, format=\"turtle\")\n",
    "\n",
    "print(\"Task 2:\")\n",
    "print(f\"Output location: {output_file}\")\n",
    "print(f\"Total triples: {len(g):,}\")\n",
    "print(f\"Recipe <-> Nutrition: {linked}/{len(nutrition_df)} linked\")\n",
    "print(f\"Recipe <-> Restaurant: via {len(cuisine_uris)} shared cuisines\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-12T17:35:55.243601Z",
     "start_time": "2026-02-12T17:35:54.673621Z"
    }
   },
   "outputs": [],
   "source": [
    "REVIEWS_TXT =\"data/Reviews.txt\"\n",
    "STRUCTURED_KG = \"outputs/KEN4256-structured-KG-team2.ttl\"\n",
    "SCHEMA_FILE = \"outputs/schema.ttl\"\n",
    "OUTPUT_DIR = \"outputs\"\n",
    "BASE_URI = \"http://kg-course.io/food-nutrition/\"\n",
    "REVIEW_LIMIT = 1000\n",
    "WIKIDATA_RECIPE_LIMIT = 1000\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "\n",
    "sparql = SPARQLWrapper(\"https://query.wikidata.org/sparql\")\n",
    "\n",
    "categories = {\n",
    "    \"fruit\": \"wd:Q3314483\",\n",
    "    \"vegetable\": \"wd:Q11004\",\n",
    "    \"meat\": \"wd:Q10976\",\n",
    "    \"fish\": \"wd:Q205149\",\n",
    "    \"milk\": \"wd:Q10979\",\n",
    "}\n",
    "\n",
    "all_ingredients_names = set()\n",
    "\n",
    "for name, cat in categories.items():\n",
    "    sparql.setQuery(f\"\"\"\n",
    "    SELECT DISTINCT ?ingredientLabel WHERE {{\n",
    "        ?ingredient wdt:P31/wdt:P279* {cat}.\n",
    "        SERVICE wikibase:label {{ bd:serviceParam wikibase:language \"en\". }}\n",
    "    }}\n",
    "    LIMIT 2000\n",
    "    \"\"\")\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    results = sparql.query().convert()\n",
    "    ingredients = [item['ingredientLabel']['value'].lower() for item in results[\"results\"][\"bindings\"]]\n",
    "    all_ingredients_names.update(ingredients)\n",
    "\n",
    "all_ingredients_list = sorted(all_ingredients_names)\n",
    "\n",
    "print(f\"Total ingredients found: {len(all_ingredients_names)}\")\n",
    "print(\"Example ingredients:\", all_ingredients_list[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-12T17:35:56.270427Z",
     "start_time": "2026-02-12T17:35:55.247602Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-12T17:35:56.979159Z",
     "start_time": "2026-02-12T17:35:56.321437Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = REVIEWS_TXT\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(file_path, sep=\"\\t\")\n",
    "\n",
    "# Drop rows where 'Review' is NaN\n",
    "df = df.dropna(subset=['Review'])\n",
    "\n",
    "# Remove rows where 'Review' is empty or contains only whitespace\n",
    "df = df[df['Review'].str.strip() != \"\"]\n",
    "\n",
    "# Select the first 1,000 reviews after cleaning\n",
    "subsection = df['Review'].iloc[0:1000]\n",
    "\n",
    "# Optional: also get corresponding RecipeId\n",
    "recipe_ids = df['RecipeId'].iloc[0:1000]\n",
    "\n",
    "print(f\"Total reviews after cleaning: {len(df)}\")\n",
    "print(f\"Selected {len(subsection)} reviews for sentiment analysis\")\n",
    "print(subsection.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-12T17:35:56.994747Z",
     "start_time": "2026-02-12T17:35:56.982160Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_ingredients(text, all_ingredients_names):\n",
    "    doc = nlp(text[:500])  # For speed\n",
    "    ingredients = set()\n",
    "\n",
    "    # Named entities\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ in ['PRODUCT', 'ORG']:\n",
    "            ingredient = ent.text.lower().strip()\n",
    "            if len(ingredient) > 2:\n",
    "                ingredients.add(ingredient)\n",
    "\n",
    "    # Common food nouns\n",
    "    food_words = {\n",
    "        'chicken', 'beef', 'pork', 'fish', 'rice', 'pasta', 'cheese',\n",
    "        'tomato', 'onion', 'garlic', 'pepper', 'salt', 'sugar',\n",
    "        'flour', 'egg', 'milk', 'butter', 'oil', 'bread',\n",
    "        'potato', 'carrot'\n",
    "    }\n",
    "\n",
    "    # Merge previously found ingredients properly\n",
    "    food_words.update(all_ingredients_names)\n",
    "\n",
    "    for token in doc:\n",
    "        word = token.text.lower().strip()\n",
    "        if word in food_words:\n",
    "            ingredients.add(word)\n",
    "\n",
    "    # Return unique list (set already ensures uniqueness)\n",
    "    return list(ingredients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-12T17:36:13.028336Z",
     "start_time": "2026-02-12T17:35:56.997748Z"
    }
   },
   "outputs": [],
   "source": [
    "sentiment_labels = []\n",
    "confidences = []\n",
    "review_data = []\n",
    "\n",
    "# Loop over reviews\n",
    "for idx, text in enumerate(subsection):\n",
    "    ingredients = extract_ingredients(text,all_ingredients_names)\n",
    "    print(ingredients)\n",
    "    inputs = tokenizer(text[:512], return_tensors=\"pt\")\n",
    "\n",
    "    # Run model\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "\n",
    "    # Convert logits to probabilities\n",
    "    probs = torch.softmax(logits, dim=1)\n",
    "\n",
    "    # Predicted class\n",
    "    predicted_class_id = logits.argmax().item()\n",
    "    label = model.config.id2label[predicted_class_id]\n",
    "    confidence = probs[0][predicted_class_id].item()\n",
    "\n",
    "    # Make sentiment score signed\n",
    "    if label.lower() == \"positive\":\n",
    "        sentiment_score = confidence\n",
    "    else:\n",
    "        sentiment_score = -confidence\n",
    "\n",
    "    # Append to lists\n",
    "    sentiment_labels.append(label)\n",
    "    confidences.append(confidence)\n",
    "    review_data.append({\n",
    "        'id': recipe_ids.iloc[idx],\n",
    "        'text': text,\n",
    "        'ingredients': ingredients,\n",
    "        'sentiment_score': sentiment_score,\n",
    "        'sentiment_label': label,\n",
    "        'confidence': confidence\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-12T17:36:13.091336Z",
     "start_time": "2026-02-12T17:36:13.078336Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_ingredients(text, all_ingredients_names):\n",
    "    doc = nlp(text[:500])  # For speed\n",
    "    ingredients = set()\n",
    "\n",
    "    # Named entities\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ in ['PRODUCT', 'ORG']:\n",
    "            ingredient = ent.text.lower().strip()\n",
    "            if len(ingredient) > 2:\n",
    "                ingredients.add(ingredient)\n",
    "\n",
    "    # Common food nouns\n",
    "    food_words = {\n",
    "        'chicken', 'beef', 'pork', 'fish', 'rice', 'pasta', 'cheese',\n",
    "        'tomato', 'onion', 'garlic', 'pepper', 'salt', 'sugar',\n",
    "        'flour', 'egg', 'milk', 'butter', 'oil', 'bread',\n",
    "        'potato', 'carrot'\n",
    "    }\n",
    "\n",
    "    # Merge previously found ingredients properly\n",
    "    food_words.update(all_ingredients_names)\n",
    "\n",
    "    for token in doc:\n",
    "        word = token.text.lower().strip()\n",
    "        if word in food_words:\n",
    "            ingredients.add(word)\n",
    "\n",
    "    # Return unique list (set already ensures uniqueness)\n",
    "    return list(ingredients)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-12T17:36:13.137844Z",
     "start_time": "2026-02-12T17:36:13.094337Z"
    }
   },
   "outputs": [],
   "source": [
    "g_unstructured = Graph()\n",
    "g_unstructured.parse(SCHEMA_FILE, format=\"turtle\") # Schema\n",
    "\n",
    "ingredient_uris = {} # Avoid duplicates\n",
    "ingredient_counter = 0\n",
    "\n",
    "for i, review in enumerate(review_data):\n",
    "    review_uri = BASE[f\"review_{i}\"]\n",
    "    g_unstructured.add((review_uri, RDF.type, BASE.Review))\n",
    "    g_unstructured.add((review_uri, BASE.hasSentimentScore,\n",
    "                        Literal(review['sentiment_score'], datatype=XSD.float)))\n",
    "    g_unstructured.add((review_uri, BASE.hasSentimentLabel,\n",
    "                        Literal(review['sentiment_label'], datatype=XSD.string)))\n",
    "    g_unstructured.add((review_uri, BASE.hasConfidence,\n",
    "                        Literal(review['confidence'], datatype=XSD.float)))\n",
    "\n",
    "    # Add ingredients\n",
    "    for ingredient_name in review['ingredients']:\n",
    "        # print(ingredient_name) # check\n",
    "        if ingredient_name not in ingredient_uris:\n",
    "            ingredient_uri = BASE[f\"ingredient_{ingredient_counter}\"]\n",
    "            g_unstructured.add((ingredient_uri, RDF.type, BASE.Ingredient))\n",
    "            g_unstructured.add((ingredient_uri, RDFS.label, Literal(ingredient_name)))\n",
    "            ingredient_uris[ingredient_name] = ingredient_uri\n",
    "            ingredient_counter += 1\n",
    "        else:\n",
    "            ingredient_uri = ingredient_uris[ingredient_name]\n",
    "\n",
    "        g_unstructured.add((review_uri, BASE.mentionsIngredient, ingredient_uri)) ## Link review to ingredient\n",
    "print(len(ingredient_uris))\n",
    "print(f\"Unstructured KG: {len(g_unstructured)} triples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-12T17:39:22.911303Z",
     "start_time": "2026-02-12T17:36:13.141845Z"
    }
   },
   "outputs": [],
   "source": [
    "# Query Wikidata for common ingredients\n",
    "from rdflib import URIRef\n",
    "\n",
    "def get_wikidata_id(ingredient_name):\n",
    "\n",
    "    sparql = SPARQLWrapper(\"https://query.wikidata.org/sparql\")\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    query = f\"\"\"\n",
    "    SELECT ?item WHERE {{\n",
    "      ?item rdfs:label \"{ingredient_name}\"@en .\n",
    "      ?item wdt:P31/wdt:P279* wd:Q2095 .  # instance of food\n",
    "    }}\n",
    "    LIMIT 1\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        sparql.setQuery(query)\n",
    "        results = sparql.query().convert()\n",
    "        if results['results']['bindings']:\n",
    "            return results['results']['bindings'][0]['item']['value']\n",
    "    except:\n",
    "        pass # It might time out\n",
    "    return None\n",
    "\n",
    "# Link top 20 ingredients (else too many queries)\n",
    "linked_count = 0\n",
    "for ingredient_name in list(ingredient_uris.keys()):\n",
    "    wikidata_uri = get_wikidata_id(ingredient_name)\n",
    "    if wikidata_uri:\n",
    "        ingredient_uri = ingredient_uris[ingredient_name]\n",
    "        g_unstructured.add((ingredient_uri, OWL.sameAs, URIRef(wikidata_uri)))\n",
    "        linked_count += 1\n",
    "\n",
    "print(f\"{linked_count} ingredients llinked\")\n",
    "print(f\"Final unstructured KG has {len(g_unstructured)} triples\")\n",
    "\n",
    "# Save\n",
    "unstructured_file = os.path.join(OUTPUT_DIR, \"KEN4256-unstructured-KG-team2.ttl\")\n",
    "g_unstructured.serialize(destination=unstructured_file, format=\"turtle\")\n",
    "print(f\"Saved to: {unstructured_file}\")\n",
    "\n",
    "# Create integrated KG (structured + unstructured)\n",
    "g_integrated = Graph()\n",
    "g_integrated.parse(STRUCTURED_KG, format=\"turtle\")\n",
    "g_integrated.parse(unstructured_file, format=\"turtle\")\n",
    "\n",
    "integrated_file = os.path.join(OUTPUT_DIR, \"KEN4256-integrated-KG-team2.ttl\")\n",
    "g_integrated.serialize(destination=integrated_file, format=\"turtle\")\n",
    "print(f\"Saved to {integrated_file}\")\n",
    "\n",
    "print(f\"Unstructured KG: {len(g_unstructured):,} triples\")\n",
    "print(f\"Integrated KG: {len(g_integrated):,} triples\")\n",
    "print(\"\")\n",
    "print(\"Stats:\")\n",
    "print(f\"{len(review_data)} reviews\")\n",
    "print(f\"{len(ingredient_uris)} unique ingredients\")\n",
    "print(f\"{linked_count} Wikidata links\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-12T17:39:43.776819Z",
     "start_time": "2026-02-12T17:39:36.156926Z"
    }
   },
   "outputs": [],
   "source": [
    "INTEGRATED_KG = os.path.join(OUTPUT_DIR, \"KEN4256-integrated-KG-team2.ttl\") \n",
    "OUTPUT_DIR = \"outputs\"\n",
    "from rdflib import Graph\n",
    "import datetime\n",
    "\n",
    "g = Graph()\n",
    "g.parse(INTEGRATED_KG, format=\"turtle\")\n",
    "print(f\"{len(g):,} triples\")\n",
    "\n",
    "def run_query(query, title): # Execute SPARQL query and return results\n",
    "    results = g.query(query)\n",
    "    print(f\"\\n{title}\\n\")\n",
    "    \n",
    "    result_list = []\n",
    "    for row in results:\n",
    "        result_list.append(row)\n",
    "        print(\" | \".join(str(val) for val in row))\n",
    "    \n",
    "    print(f\"\\n{len(result_list)} result(s)\")\n",
    "    return result_list, query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-12T17:39:44.278709Z",
     "start_time": "2026-02-12T17:39:43.826822Z"
    }
   },
   "outputs": [],
   "source": [
    "query_1 = \"\"\"\n",
    "PREFIX : <http://kg-course.io/food-nutrition/>\n",
    "PREFIX schema: <http://schema.org/>\n",
    "\n",
    "SELECT DISTINCT ?recipeName\n",
    "WHERE {\n",
    "    ?recipe a :Recipe ;\n",
    "            schema:name ?recipeName ;\n",
    "            schema:recipeIngredient ?ingredients .\n",
    "    \n",
    "    FILTER(CONTAINS(LCASE(STR(?ingredients)), \"mango\"))\n",
    "}\n",
    "ORDER BY ?recipeName\n",
    "LIMIT 20\n",
    "\"\"\"\n",
    "\n",
    "results_1, _ = run_query(query_1, \"4.1: Recipes wigth mango\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-12T17:39:45.062599Z",
     "start_time": "2026-02-12T17:39:44.281708Z"
    }
   },
   "outputs": [],
   "source": [
    "query_2 = \"\"\"\n",
    "PREFIX : <http://kg-course.io/food-nutrition/>\n",
    "PREFIX schema: <http://schema.org/>\n",
    "\n",
    "SELECT DISTINCT ?recipeName ?cookTime ?keywords\n",
    "WHERE {\n",
    "    ?recipe a :Recipe ;\n",
    "            schema:name ?recipeName ;\n",
    "            schema:cookTime ?cookTime ;\n",
    "            schema:keywords ?keywords .\n",
    "    \n",
    "    # Contains 'pie' AND 'healthy'\n",
    "    FILTER(CONTAINS(LCASE(?recipeName), \"pie\") || CONTAINS(LCASE(?keywords), \"pie\"))\n",
    "    FILTER(CONTAINS(LCASE(?keywords), \"healthy\"))\n",
    "    \n",
    "    FILTER( # Check for PT formats with hours < 2 or only minutes\n",
    "        CONTAINS(?cookTime, \"PT\") && \n",
    "        (!CONTAINS(?cookTime, \"H\") || \n",
    "         CONTAINS(?cookTime, \"PT0\") || \n",
    "         CONTAINS(?cookTime, \"PT1H\"))\n",
    "    )\n",
    "}\n",
    "ORDER BY ?recipeName\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "results_2, _ = run_query(query_2, \"4.2: Healthy pies < 2h cooktime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-12T17:39:54.757798Z",
     "start_time": "2026-02-12T17:39:45.066600Z"
    }
   },
   "outputs": [],
   "source": [
    "query_3 = \"\"\"\n",
    "PREFIX : <http://kg-course.io/food-nutrition/>\n",
    "PREFIX schema: <http://schema.org/>\n",
    "\n",
    "SELECT DISTINCT ?restaurantName ?address\n",
    "WHERE {\n",
    "    ?restaurant a :Restaurant ;\n",
    "                schema:name ?restaurantName ;\n",
    "                schema:addressLocality ?city ;\n",
    "                :hasOnlineDelivery ?delivery ;\n",
    "                :servesCuisine ?cuisine .\n",
    "    \n",
    "    ?cuisine schema:name ?cuisineName .\n",
    "    \n",
    "    OPTIONAL { ?restaurant schema:address ?address . }\n",
    "    FILTER(LCASE(STR(?city)) = \"new delhi\")\n",
    "    FILTER(CONTAINS(LCASE(STR(?cuisineName)), \"chinese\"))\n",
    "    FILTER(?delivery = true)\n",
    "}\n",
    "ORDER BY ?restaurantName\n",
    "LIMIT 20\n",
    "\"\"\"\n",
    "\n",
    "results_3, _ = run_query(query_3, \"4.3: New Delhi chinese restaurants with delivery\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-12T17:40:04.193141Z",
     "start_time": "2026-02-12T17:39:54.821734Z"
    }
   },
   "outputs": [],
   "source": [
    "query_4 = \"\"\"\n",
    "PREFIX : <http://kg-course.io/food-nutrition/>\n",
    "PREFIX schema: <http://schema.org/>\n",
    "\n",
    "SELECT (AVG(?cost) AS ?avgCost)\n",
    "WHERE {\n",
    "    ?restaurant a :Restaurant ;\n",
    "                schema:addressLocality ?city ;\n",
    "                :averageCostForTwo ?cost ;\n",
    "                :servesCuisine ?cuisine .\n",
    "    \n",
    "    ?cuisine schema:name ?cuisineName .\n",
    "    \n",
    "    FILTER(CONTAINS(LCASE(STR(?city)), \"davenport\"))\n",
    "    \n",
    "    # Asian cuisines\n",
    "    FILTER(\n",
    "        CONTAINS(LCASE(STR(?cuisineName)), \"indian\") ||\n",
    "        CONTAINS(LCASE(STR(?cuisineName)), \"sushi\") ||\n",
    "        CONTAINS(LCASE(STR(?cuisineName)), \"asian\") ||\n",
    "        CONTAINS(LCASE(STR(?cuisineName)), \"chinese\") ||\n",
    "        CONTAINS(LCASE(STR(?cuisineName)), \"thai\")\n",
    "    )\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "results_4, _ = run_query(query_4, \"4.4: avg cost Davenport (asian food)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-12T17:40:06.182989Z",
     "start_time": "2026-02-12T17:40:04.244145Z"
    }
   },
   "outputs": [],
   "source": [
    "query_5 = \"\"\"\n",
    "PREFIX : <http://kg-course.io/food-nutrition/>\n",
    "PREFIX schema: <http://schema.org/>\n",
    "PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>\n",
    "\n",
    "SELECT DISTINCT ?recipeName ?calories ?image ?datePublished\n",
    "WHERE {\n",
    "    ?recipe a :Recipe ;\n",
    "            schema:name ?recipeName ;\n",
    "            schema:recipeCategory ?category ;\n",
    "            schema:keywords ?keywords ;\n",
    "            :hasNutrition ?nutrition .\n",
    "    \n",
    "    ?nutrition schema:calories ?calories .\n",
    "    \n",
    "    OPTIONAL { ?recipe schema:image ?image . }\n",
    "    OPTIONAL { ?recipe schema:datePublished ?datePublished . }\n",
    "    \n",
    "    FILTER(CONTAINS(LCASE(?category), \"dessert\"))\n",
    "    FILTER(CONTAINS(LCASE(?keywords), \"easy\"))\n",
    "    FILTER(?calories < 300)\n",
    "    \n",
    "    # After 2000 (check dates)\n",
    "    FILTER(\n",
    "        !BOUND(?datePublished) ||\n",
    "        (CONTAINS(STR(?datePublished), \"200\") ||\n",
    "         CONTAINS(STR(?datePublished), \"201\") ||\n",
    "         CONTAINS(STR(?datePublished), \"202\"))\n",
    "    )\n",
    "}\n",
    "ORDER BY ?calories\n",
    "LIMIT 5\n",
    "\"\"\"\n",
    "\n",
    "results_5, _ = run_query(query_5, \"4.5: Top 5 easy desserts < 300 cal(after 2000)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-12T17:40:07.860330Z",
     "start_time": "2026-02-12T17:40:06.231495Z"
    }
   },
   "outputs": [],
   "source": [
    "query_6 = \"\"\"\n",
    "PREFIX : <http://kg-course.io/food-nutrition/>\n",
    "PREFIX schema: <http://schema.org/>\n",
    "SELECT ?recipeName ?avgSentiment ?prepTime ?sugar\n",
    "WHERE {\n",
    "    ?recipe a :Recipe ;\n",
    "            schema:name ?recipeName ;\n",
    "            schema:recipeCategory ?category ;\n",
    "            :hasNutrition ?nutrition .\n",
    "    OPTIONAL { ?recipe schema:prepTime ?prepTime . }\n",
    "    OPTIONAL { ?nutrition schema:sugarContent ?sugar . }\n",
    "    \n",
    "    # Avg sentiment from reviews\n",
    "    {\n",
    "        SELECT ?recipe (AVG(?score) AS ?avgSentiment)\n",
    "        WHERE {\n",
    "            ?recipe :hasReview ?review .\n",
    "            ?review :hasSentimentScore ?score .\n",
    "        }\n",
    "        GROUP BY ?recipe\n",
    "    }\n",
    "    \n",
    "    FILTER(CONTAINS(LCASE(?category), \"beverage\") || CONTAINS(LCASE(?category), \"drink\")) # Category\n",
    "}\n",
    "ORDER BY DESC(?avgSentiment)\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "results_6, _ = run_query(query_6, \"4.6: Top 10 highly rated beverages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-12T17:40:08.364259Z",
     "start_time": "2026-02-12T17:40:07.924713Z"
    }
   },
   "outputs": [],
   "source": [
    "query_7 = \"\"\"\n",
    "PREFIX : <http://kg-course.io/food-nutrition/>\n",
    "PREFIX schema: <http://schema.org/>\n",
    "\n",
    "SELECT ?recipeName ?protein ?avgSentiment ?cuisineName ?usaCount\n",
    "       (IF(?usaCount >= 5, true, false) AS ?cuisineCommonInUSA)\n",
    "WHERE {\n",
    "    ?recipe a :Recipe ;\n",
    "            schema:name ?recipeName ;\n",
    "            :hasNutrition ?nutrition ;\n",
    "            :hasCuisine ?cuisine .\n",
    "\n",
    "    ?nutrition schema:proteinContent ?protein .\n",
    "    FILTER(?protein > 20)\n",
    "\n",
    "    ?cuisine schema:name ?cuisineName .\n",
    "\n",
    "    #\"Highest-rated\" recipes = average sentiment from reviews\n",
    "    {\n",
    "        SELECT ?recipe (AVG(?score) AS ?avgSentiment)\n",
    "        WHERE {\n",
    "            ?recipe :hasReview ?review .\n",
    "            ?review :hasSentimentScore ?score .\n",
    "        }\n",
    "        GROUP BY ?recipe\n",
    "    }\n",
    "\n",
    "\n",
    "    BIND(COALESCE(?usaRestaurantCount, 0) AS ?usaCount)\n",
    "}\n",
    "ORDER BY DESC(?avgSentiment) DESC(?protein)\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "results_7, _ = run_query(query_7, \"4.7: Highest-rated protein-rich recipes + cuisine availability in USA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-12T17:40:09.153337Z",
     "start_time": "2026-02-12T17:40:08.367259Z"
    }
   },
   "outputs": [],
   "source": [
    "query_8 = \"\"\"\n",
    "PREFIX : <http://kg-course.io/food-nutrition/>\n",
    "PREFIX schema: <http://schema.org/>\n",
    "SELECT ?recipeName ?nds ?avgSentiment ?restaurantRating ?cuisineName\n",
    "WHERE {\n",
    "    ?recipe a :Recipe ;\n",
    "            schema:name ?recipeName ;\n",
    "            :hasNutrition ?nutrition ;\n",
    "            :hasCuisine ?cuisine .\n",
    "    \n",
    "    ?nutrition schema:proteinContent ?protein ;\n",
    "               schema:fiberContent ?fiber ;\n",
    "               schema:sugarContent ?sugar .\n",
    "    \n",
    "    ?cuisine schema:name ?cuisineName .\n",
    "    \n",
    "    # Calculate NDS: (1.0 × Protein) + (1.5 × Fiber) − (2.0 × Sugar)\n",
    "    BIND((1.0 * ?protein) + (1.5 * ?fiber) - (2.0 * ?sugar) AS ?nds)\n",
    "    # Avg sentiment from reviews\n",
    "    OPTIONAL {\n",
    "        {\n",
    "            SELECT ?recipe (AVG(?score) AS ?avgSentiment)\n",
    "            WHERE {\n",
    "                ?recipe :hasReview ?review .\n",
    "                ?review :hasSentimentScore ?score .\n",
    "            }\n",
    "            GROUP BY ?recipe\n",
    "        }\n",
    "    }\n",
    "    FILTER(?nds > 0)\n",
    "}\n",
    "ORDER BY DESC(?nds)\n",
    "LIMIT 5\n",
    "\"\"\"\n",
    "\n",
    "results_8, _ = run_query(query_8, \"4.8: Top 5 healthiest recipes by NDS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-12T17:40:09.168851Z",
     "start_time": "2026-02-12T17:40:09.158846Z"
    }
   },
   "outputs": [],
   "source": [
    "# Collate\n",
    "all_queries = [\n",
    "    (\"4.1\", query_1, results_1),\n",
    "    (\"4.2\", query_2, results_2),\n",
    "    (\"4.3\", query_3, results_3),\n",
    "    (\"4.4\", query_4, results_4),\n",
    "    (\"4.5\", query_5, results_5),\n",
    "    (\"4.6\", query_6, results_6),\n",
    "    (\"4.7\", query_7, results_7),\n",
    "    (\"4.8\",  query_8, results_8),\n",
    "]\n",
    "\n",
    "output_file = os.path.join(OUTPUT_DIR, \"SPARQL_query_results.txt\")\n",
    "with open(output_file, 'w', encoding='utf-8') as f:\n",
    "    f.write(\"Task 4:\\n\")\n",
    "    for num, query, results in all_queries:\n",
    "        f.write(f\"\\nQuery {num}\\n\")\n",
    "        f.write(\"\\nSPARQL Query:\\n\")\n",
    "        f.write(query.strip() + \"\\n\\n\")\n",
    "        f.write(\"\\nResults:\\n\")        \n",
    "        if results:\n",
    "            for i, row in enumerate(results, 1):\n",
    "                f.write(f\"{i}. \" + \" | \".join(str(val) for val in row) + \"\\n\")\n",
    "            f.write(f\"\\nTOTAL: {len(results)} result(s)\\n\")\n",
    "        else:\n",
    "            f.write(\"No results found.\\n\")\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "# for individual files\n",
    "for num, query, results in all_queries:\n",
    "    per_query_file = os.path.join(OUTPUT_DIR, f\"query_{num.replace('.', '_')}.txt\")\n",
    "    with open(per_query_file, 'w', encoding='utf-8') as f:\n",
    "        f.write(\"Task 4:\\n\")\n",
    "        f.write(f\"\\nQuery {num}\\n\")\n",
    "        f.write(\"\\nSPARQL Query:\\n\")\n",
    "        f.write(query.strip() + \"\\n\\n\")\n",
    "        f.write(\"\\nResults:\\n\")\n",
    "        if results:\n",
    "            for i, row in enumerate(results, 1):\n",
    "                f.write(f\"{i}. \" + \" | \".join(str(val) for val in row) + \"\\n\")\n",
    "            f.write(f\"\\nTOTAL: {len(results)} result(s)\\n\")\n",
    "        else:\n",
    "            f.write(\"No results found.\\n\")\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "print(f\"Task 4 - combined results saved toL {output_file}\")\n",
    "print(f\"\\nNo. of results for each query:\")\n",
    "for num, _, results in all_queries:\n",
    "    print(f\"Query #{num}: {len(results)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kg-py313",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
